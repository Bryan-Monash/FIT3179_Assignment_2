{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20593fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"ridership_headline.csv\")\n",
    "\n",
    "# 1. Fill empty values (NaN) with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# 2. Remove all bus columns\n",
    "df = df.drop(columns=[c for c in df.columns if c.startswith(\"bus_\")])\n",
    "\n",
    "# 3. Combine ETS, Intercity, Komuter_Utara, Tebrau, and Komuter into one column\n",
    "df[\"rail_komuter\"] = (\n",
    "    df[\"rail_ets\"]\n",
    "    + df[\"rail_intercity\"]\n",
    "    + df[\"rail_komuter_utara\"]\n",
    "    + df[\"rail_tebrau\"]\n",
    "    + df[\"rail_komuter\"]\n",
    ")\n",
    "\n",
    "# 4. Drop the old columns (optional)\n",
    "df = df.drop(columns=[\"rail_ets\", \"rail_intercity\", \"rail_komuter_utara\", \"rail_tebrau\"])\n",
    "\n",
    "df.rename(columns={\n",
    "    \"rail_lrt_ampang\": \"Ampang Line\",\n",
    "    \"rail_lrt_kj\": \"Kelana Jaya Line\",\n",
    "    \"rail_monorail\": \"KL Monorail\",\n",
    "    \"rail_mrt_pjy\": \"Putrajaya Line\",\n",
    "    \"rail_mrt_kajang\": \"Kajang Line\",\n",
    "    \"rail_komuter\": \"KTM\"\n",
    "}, inplace=True)\n",
    "\n",
    "# 1. Ensure date is parsed as datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# 2. Extract year\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "\n",
    "# 3. Group by year and sum numeric columns\n",
    "df_yearly = df.groupby(\"year\", as_index=False).sum(numeric_only=True)\n",
    "\n",
    "df_yearly = df_yearly.melt(\n",
    "    id_vars=[\"year\"],\n",
    "    var_name=\"route_line\",\n",
    "    value_name=\"total_ridership\"\n",
    ")\n",
    "df_yearly = df_yearly.pivot(\n",
    "    index=\"route_line\",\n",
    "    columns=\"year\",\n",
    "    values=\"total_ridership\"\n",
    ")\n",
    "\n",
    "df_yearly.columns = [f\"ridership_{int(c)}\" for c in df_yearly.columns]\n",
    "\n",
    "df_yearly = df_yearly.reset_index()\n",
    "\n",
    "# 4. Save to new file\n",
    "df_yearly.to_csv(\"transport_yearly_sum.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d66a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your original daily CSV\n",
    "df = pd.read_csv(\"ridership_headline.csv\")\n",
    "\n",
    "# Fill empty values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Combine ETS, Intercity, Komuter_Utara, Tebrau, and Komuter into one commuter column\n",
    "df[\"rail_komuter_total\"] = (\n",
    "    df[\"rail_ets\"] +\n",
    "    df[\"rail_intercity\"] +\n",
    "    df[\"rail_komuter_utara\"] +\n",
    "    df[\"rail_tebrau\"] +\n",
    "    df[\"rail_komuter\"]\n",
    ")\n",
    "\n",
    "# Keep only the rail lines you want\n",
    "df = df[[\"date\",\"rail_lrt_ampang\",\"rail_mrt_kajang\",\"rail_lrt_kj\",\"rail_monorail\",\"rail_mrt_pjy\",\"rail_komuter_total\"]]\n",
    "\n",
    "df.rename(columns={\n",
    "    \"rail_lrt_ampang\": \"Ampang Line\",\n",
    "    \"rail_lrt_kj\": \"Kelana Jaya Line\",\n",
    "    \"rail_monorail\": \"KL Monorail\",\n",
    "    \"rail_mrt_pjy\": \"Putrajaya Line\",\n",
    "    \"rail_mrt_kajang\": \"Kajang Line\",\n",
    "    \"rail_komuter_total\": \"KTM\"\n",
    "}, inplace=True)\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df[(df[\"date\"].dt.year >= 2020) & (df[\"date\"].dt.year <= 2024)]\n",
    "\n",
    "# Pivot longer so each row = route + day\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"date\"], \n",
    "    value_vars=[\"Ampang Line\",\"Kajang Line\",\"Kelana Jaya Line\",\"KL Monorail\",\"Putrajaya Line\",\"KTM\"],\n",
    "    var_name=\"route_line\", \n",
    "    value_name=\"ridership\"\n",
    ")\n",
    "\n",
    "# Save CSV\n",
    "df_long.to_csv(\"ridership_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b23b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Putrajaya Line' 'KTM' 'Kajang Line' 'Kelana Jaya Line' 'KL Monorail'\n",
      " 'Ampang Line']\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(\"../map_data/routes_selangor.geojson\")\n",
    "gdf = gdf[gdf[\"name:en\"].str.contains(\"Kelana Jaya|Ampang|Putrajaya|Kajang|KTM|Monorail\", case=False, na=False)]\n",
    "gdf[\"name:en\"] = gdf[\"name:en\"].replace(\n",
    "    {\"Ampang and Sri Petaling Lines\" : \"Ampang Line\"}\n",
    ")\n",
    "print(gdf[\"name:en\"].unique())\n",
    "gdf.to_file(\"routes_selangor2.geojson\", driver=\"GeoJSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fe9104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ampang Line' 'Kelana Jaya Line' 'KTM' 'KL Monorail' 'Kajang Line'\n",
      " 'Putrajaya Line']\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(\"../map_data/routes.geojson\")\n",
    "gdf = gdf[gdf[\"name:en\"].str.contains(\"Kelana Jaya|Ampang|Putrajaya|Kajang|KTM|Monorail\", case=False, na=False)]\n",
    "gdf[\"name:en\"] = gdf[\"name:en\"].replace(\n",
    "    {\"Ampang and Sri Petaling Lines\" : \"Ampang Line\"}\n",
    ")\n",
    "print(gdf[\"name:en\"].unique())\n",
    "gdf.to_file(\"routes2.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f1d4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  ron95  ron97\n",
      "41 2024-12-26   2.05   3.25\n",
      "42 2024-12-19   2.05   3.22\n",
      "43 2024-12-12   2.05   3.19\n",
      "44 2024-12-05   2.05   3.19\n",
      "45 2024-11-28   2.05   3.19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv('fuelprice.csv')\n",
    "\n",
    "# Ensure 'date' is parsed as datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Filter: series == 'level'\n",
    "df = df[df['series_type'] == 'level']\n",
    "\n",
    "# Keep only needed columns (make sure they exist)\n",
    "columns_to_keep = ['date', 'ron95', 'ron97']\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# Filter date range: 2020 - 2024 inclusive\n",
    "df = df[(df['date'].dt.year >= 2020) & (df['date'].dt.year <= 2024)]\n",
    "\n",
    "# Save filtered data (optional)\n",
    "df.to_csv('fuelprice_filtered.csv', index=False)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d58d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population columns: ['year', 'state', 'district', 'sex', 'age', 'ethnicity', 'population']\n",
      "Area columns: ['district', 'area_km2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV files\n",
    "df = pd.read_csv(\"population_district_filtered.csv\")\n",
    "df_area = pd.read_csv(\"district_area.csv\")\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "df_area.columns = df_area.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "print(\"Population columns:\", df.columns.tolist())\n",
    "print(\"Area columns:\", df_area.columns.tolist())\n",
    "\n",
    "# Convert population to absolute numbers\n",
    "df[\"population_absolute\"] = df[\"population\"] * 1000\n",
    "\n",
    "# Merge and calculate density\n",
    "merged_df = pd.merge(df, df_area, on=\"district\", how=\"left\")\n",
    "merged_df[\"population_density\"] = merged_df[\"population_absolute\"] / merged_df[\"area_km2\"]\n",
    "\n",
    "# Filter and export\n",
    "filtered_df = merged_df[(merged_df[\"year\"] >= 2020) & (merged_df[\"year\"] <= 2024)]\n",
    "filtered_df.to_csv(\"population_district_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70066d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations CRS: EPSG:4326\n",
      "States CRS: None\n",
      "             state         lon       lat  subway  monorail  light_rail  train\n",
      "0         Selangor  101.498803  3.272825    61.0       7.0       109.0   74.0\n",
      "1            Johor  103.388997  2.051154     0.0       0.0         0.0   22.0\n",
      "2     Kuala Lumpur  101.690030  3.143704    70.0      20.0        81.0   49.0\n",
      "3          Malacca  102.304435  2.323464     0.0       0.0         0.0    4.0\n",
      "4  Negeri Sembilan  102.206719  2.775065     0.0       0.0         0.0   27.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7588\\3658499637.py:41: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  states[\"lon\"] = states.geometry.centroid.x\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7588\\3658499637.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  states[\"lat\"] = states.geometry.centroid.y\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Load files\n",
    "stations = gpd.read_file(\"../map_data/stations.geojson\")\n",
    "states = gpd.read_file(\"../map_data/geoBoundaries-MYS-ADM1.topojson\")\n",
    "\n",
    "# --- Check CRS ---\n",
    "print(\"Stations CRS:\", stations.crs)\n",
    "print(\"States CRS:\", states.crs)\n",
    "\n",
    "# --- If CRS is missing, assume WGS84 (EPSG:4326) ---\n",
    "if stations.crs is None:\n",
    "    stations = stations.set_crs(\"EPSG:4326\")\n",
    "if states.crs is None:\n",
    "    states = states.set_crs(\"EPSG:4326\")\n",
    "\n",
    "# --- Now convert to same CRS ---\n",
    "stations = stations.to_crs(states.crs)\n",
    "\n",
    "# --- Proceed with spatial join ---\n",
    "stations_with_state = gpd.sjoin(stations, states, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# --- Define transport modes ---\n",
    "transport_modes = [\"subway\", \"monorail\", \"light_rail\", \"train\"]\n",
    "\n",
    "# --- Replace missing columns or values ---\n",
    "for mode in transport_modes:\n",
    "    if mode not in stations_with_state.columns:\n",
    "        stations_with_state[mode] = \"no\"\n",
    "    stations_with_state[mode] = stations_with_state[mode].fillna(\"no\")\n",
    "\n",
    "# --- Count 'yes' values for each mode per state ---\n",
    "state_counts = (\n",
    "    stations_with_state.groupby(\"shapeName\")[transport_modes]\n",
    "    .apply(lambda x: (x == \"yes\").sum())\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# --- Add state centroid coordinates ---\n",
    "states[\"lon\"] = states.geometry.centroid.x\n",
    "states[\"lat\"] = states.geometry.centroid.y\n",
    "\n",
    "# --- Merge counts with state centroids ---\n",
    "state_summary = states[[\"shapeName\", \"lon\", \"lat\"]].merge(state_counts, on=\"shapeName\", how=\"left\")\n",
    "state_summary = state_summary.fillna(0)\n",
    "\n",
    "state_summary.rename(columns={\"shapeName\": \"state\"}, inplace=True)\n",
    "\n",
    "# --- Save to CSV ---\n",
    "state_summary.to_csv(\"station_count_by_state.csv\", index=False)\n",
    "\n",
    "print(state_summary.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
